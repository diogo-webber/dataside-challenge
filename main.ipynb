{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "44ac7ea4",
   "metadata": {},
   "source": [
    "<hr>\n",
    "\n",
    "## How to use:\n",
    "\n",
    "- Install the dependencies:\n",
    "    ```shell\n",
    "        python -m pip install -r requirements.txt\n",
    "    ```\n",
    "    \n",
    "- Request an free open weather API key **[here](https://home.openweathermap.org/api_keys)**, you will need to make an account.\n",
    "<br>\n",
    "\n",
    "- Create a file called `.env` and set a variable with your open weather API key.\n",
    "    ```shell\n",
    "        OPEN_WEATHER_API_KEY = \"key\"\n",
    "    ```\n",
    "\n",
    "- Run all cells.\n",
    "\n",
    "<hr>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "580dd39c-f066-4c32-af47-648eb71f5918",
   "metadata": {
    "tags": []
   },
   "source": [
    "- Imports and setting variables."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "a1cb6c40-3073-43b0-b7f4-95e7c9dd8245",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "import findspark\n",
    "findspark.init()\n",
    "\n",
    "import copy\n",
    "import dotenv\n",
    "import requests\n",
    "import pandas as pd\n",
    "from pyspark.sql import SparkSession\n",
    "\n",
    "TARGET_REGION_ID = 3513\n",
    "_OPEN_WEATHER_API_KEY = dotenv.get_key(key_to_get=\"OPEN_WEATHER_API_KEY\", dotenv_path=\".env\")\n",
    "\n",
    "if _OPEN_WEATHER_API_KEY == \"\":\n",
    "    raise Exception('\".env\" file don\\'t contains the API key.\\nPlease, read the instructions at the top of the file.')\n",
    "\n",
    "IBGE_API_URL = f\"https://servicodados.ibge.gov.br/api/v1/localidades/mesorregioes/{TARGET_REGION_ID}/municipios\"\n",
    "\n",
    "_CITY = \"{city}\"\n",
    "_LANG = \"pt_br\"\n",
    "_UNIT = \"metric\"\n",
    "_STATE = \"São Paulo,076\"\n",
    "OPEN_WEATHER_API_URL = f\"http://api.openweathermap.org/data/2.5/forecast?q={_CITY},{_STATE}&lang={_LANG}&units={_UNIT}&appid={_OPEN_WEATHER_API_KEY}\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "adaac33e",
   "metadata": {},
   "outputs": [],
   "source": [
    "class SQL:\n",
    "    TABLE_1 = \"\"\"\n",
    "        SELECT \n",
    "            c.nome AS Cidade, \n",
    "            c.id AS CodigoDaCidade, \n",
    "            from_unixtime(f.dt, \"yyyy-MM-dd\") AS Data, \n",
    "            c.microrregiao_nome AS Regiao, \n",
    "            i.city_country AS Pais, \n",
    "            i.city_coord_lat AS Latitude, \n",
    "            i.city_coord_lon AS Longitude, \n",
    "            f.main_temp_max AS TemperaturaMaxima, \n",
    "            f.main_temp_min AS TemperaturaMinima, \n",
    "            f.main_temp AS TemperaturaMedia,\n",
    "            \n",
    "            CASE WHEN f.weather_id < 600 THEN 'Sim'\n",
    "            ELSE 'Não' END\n",
    "            AS VaiChover, \n",
    "            \n",
    "            f.pop AS ChanceDeChuva, \n",
    "            f.weather_description AS CondicaoDoTempo, \n",
    "            from_unixtime(i.city_sunrise,\"HH:mm\") AS NascerDoSol, \n",
    "            from_unixtime(i.city_sunset,\"HH:mm\") AS PorDoSol, \n",
    "            f.wind_speed AS VelocidadeMaximaDoVento \n",
    "        FROM \n",
    "            cities AS c \n",
    "        INNER JOIN forecasts f ON c.nome=f.city \n",
    "        INNER JOIN cities_info i ON c.nome=i.city_name;\n",
    "    \"\"\"\n",
    "    \n",
    "    TABLE_2 = \"\"\"\n",
    "        SELECT \n",
    "            Cidade,\n",
    "            \n",
    "            SUM(CASE WHEN VaiChover = 'Sim' THEN 1 \n",
    "            ELSE 0 END) AS QtdDiasVaiChover,\n",
    "            \n",
    "            SUM(CASE WHEN VaiChover = 'Não' THEN 1 \n",
    "            ELSE 0 END) AS QtdDiasNaoVaiChover,\n",
    "            \n",
    "            COUNT(Cidade) AS TotalDiasMapeados\n",
    "        FROM \n",
    "            table_1\n",
    "        GROUP BY\n",
    "            Cidade\n",
    "        ORDER BY\n",
    "            Cidade;\n",
    "        \"\"\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac5eea4f",
   "metadata": {},
   "source": [
    "- Creates the **pyspark** session."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "23378d8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "spark = SparkSession.builder \\\n",
    "    .master(\"local[1]\") \\\n",
    "    .appName(\"SparkNotebook\") \\\n",
    "    .config('spark.sql.session.timeZone', 'America/Sao_Paulo') \\\n",
    "    .getOrCreate()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a97ffb2d",
   "metadata": {},
   "source": [
    "- Requests cities data by calling the **IBGE API**.\n",
    "- Create a temporary view called `\"cities\"`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e39cc758",
   "metadata": {},
   "outputs": [],
   "source": [
    "ibge_response = requests.get(IBGE_API_URL).json()\n",
    "\n",
    "cities_pandas_df = pd.json_normalize(data=ibge_response, sep=\"_\")\n",
    "\n",
    "cities_df = spark.createDataFrame(data=cities_pandas_df) \\\n",
    "    .filter(f\"microrregiao_mesorregiao_id == {TARGET_REGION_ID}\")\n",
    "\n",
    "cities_df.createOrReplaceTempView(\"cities\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9b54e976",
   "metadata": {},
   "source": [
    "- Requests the forecast data for each city by calling the Open Weather API and appends it into a list."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "e76d0cd8",
   "metadata": {},
   "outputs": [],
   "source": [
    "def weather_request(city):\n",
    "    return requests.get(OPEN_WEATHER_API_URL.format(city=city)).json()\n",
    "\n",
    "weather_data_all_cities = [weather_request(row.nome) for row in cities_df.collect()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1a094394",
   "metadata": {},
   "source": [
    "- Creates two DFs and temp views for:<br>\n",
    "    1. Cities informations;<br>\n",
    "    2. Cities forecasts;<br>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "73007dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "def extract_forecasts_for_city(city_data):\n",
    "    \"\"\"Extract the forecasts for 5 days.\n",
    "\n",
    "    Args:\n",
    "        `city_data (dict):` The response returned by the Open Weather API.\n",
    "\n",
    "    Returns:\n",
    "        `Pandas Daframe:` A dataframe containing the forecasts for the city.\n",
    "    \"\"\"\n",
    "    weather_data = city_data['list']\n",
    "\n",
    "    day_count = 1\n",
    "    forecasts_dfs = []\n",
    "    \n",
    "    for data in weather_data:\n",
    "        # Collects only one data entry per day:\n",
    "        if data[\"dt_txt\"].find(\"12:00:00\") != -1:\n",
    "            \n",
    "            # Fix a problem with some weather dicts inside lists.\n",
    "            if isinstance(data[\"weather\"], list):\n",
    "                data[\"weather\"] = data[\"weather\"][0]\n",
    "                \n",
    "            data[\"city\"] = city_data[\"city\"][\"name\"]\n",
    "                        \n",
    "            pandas_df = pd.json_normalize(data=data, sep=\"_\")\n",
    "            forecasts_dfs.append(pandas_df)\n",
    "            \n",
    "            if day_count >= 5: break\n",
    "            day_count += 1\n",
    "\n",
    "    # Clears the dict for later use\n",
    "    del city_data['list']\n",
    "    del city_data['message']\n",
    "    del city_data['cod']\n",
    "    del city_data['cnt']\n",
    "    \n",
    "    return pd.concat(forecasts_dfs, ignore_index = True, axis=0)\n",
    "\n",
    "# ------------------------------------------------------------------- #\n",
    "\n",
    "weather_data_all_cities_copy = copy.deepcopy(weather_data_all_cities)\n",
    "\n",
    "# Separate forecast DF for each city.\n",
    "forecasts_dfs = [extract_forecasts_for_city(city_data_dict) for city_data_dict in weather_data_all_cities_copy]\n",
    "\n",
    "# Joining them into one DF.\n",
    "forecasts_table_df = pd.concat(forecasts_dfs, ignore_index = True, axis=0)\n",
    "\n",
    "# Create DF with forecasts.\n",
    "spark.createDataFrame(forecasts_table_df).createOrReplaceTempView(\"forecasts\")\n",
    "\n",
    "# ------------------------------------------------------------------- #\n",
    "\n",
    "city_info_pd_dfs = [pd.json_normalize(data=city_data_dict, sep=\"_\") for city_data_dict in weather_data_all_cities_copy]\n",
    "city_infos_pd_df = pd.concat(city_info_pd_dfs, ignore_index = True, axis=0)\n",
    "\n",
    "# Just to not insert the city info in each forecast.\n",
    "spark.createDataFrame(city_infos_pd_df).createOrReplaceTempView(\"cities_info\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "20ded2fc",
   "metadata": {},
   "source": [
    "- Creates data frames for table 1 and 2."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "708561aa",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1 = spark.sql(SQL.TABLE_1)\n",
    "table_1.createOrReplaceTempView(\"table_1\")\n",
    "\n",
    "table_2 = spark.sql(SQL.TABLE_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e1245b8e",
   "metadata": {},
   "source": [
    "- Exports the tables to CSV."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "680f5189",
   "metadata": {},
   "outputs": [],
   "source": [
    "table_1.toPandas().to_csv(\"tabela_1.csv\", sep=\"|\", index=False)\n",
    "table_2.toPandas().to_csv(\"tabela_2.csv\", sep=\"|\", index=False)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05c2e344",
   "metadata": {},
   "source": [
    "### Some considerations:\n",
    "\n",
    "The data returned by the **Open Weather API** does not appear to be entirely correct.<br>\n",
    "\n",
    "The chance of rain always seems to be 0% and the maximum and minimum temperature is the same. <br>\n",
    "Which is the \"default\" for the 5-days forecast endpoint.\n",
    "\n",
    "But I believe it does not interfere with the data extraction itself."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.10.5 ('venv': venv)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.5"
  },
  "vscode": {
   "interpreter": {
    "hash": "ee4ce97230d601ef523748e69df7c293ec31b3478694e146714027d457a96e87"
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
